# Probability

## Introduction to probability

### Why study probability?

Probability and statistics are closely related. When we analyse data, we need to ask: is this data due to chance alone or is there some underlying pattern?
Probability is the study of chance.
Probability assigns a number between \(0\) and \(1\) to how likely an event is to happen. A probability of \(0\) means that the event is impossible; a probability of \(1\) means the event is certain to happen. The higher the probability, the more likely the event is to happen. A probability of \(0.5\) means that an event is just as likely to happen as it is to not happen ("50/50 chance", "even chance").

<p style="text-align: center;"><img src="images/07/probability.png" alt="" width="399" height="143" role="presentation" class="img-responsive atto_image_button_text-bottom"><p style="text-align: center;">

<h5>Notation for probability</h5>
The "probability of event \(A\)" is usually expressed as \(P(A)\). The probability of landing on Heads if you toss a coin could therefore be expressed as \(P(H)\) where \(H\) stands for the number of heads.

<h5>Numerical representation</h5>
The values for probability lie between 0 and 1. They can be expressed as

<ul><li>a fraction, for instance \(\frac12\),</li>
<li>a decimal number, for instance 0.5,</li>
<li>a percentage, for instance 50%,</li>
<li>a chance, for instance: 1 in 2 chance,</li>
<li>a ratio: 1:1.</li></ul>

These equivalent expressions are often used interchangeably and can be used for any probability we wish to represent. For example, consider the event of throwing a five on a fair die. The probability of this is\( \frac16 \) which we can express this as:

<ul><li>a fraction: \( \frac16 \),</li>
<li>a decimal number: 0.167 (rounded to three significant figures),</li>
<li>a percentage: approximately 16.7% (rounded to three significant figures),</li>
<li>a chance: a 1 in 6 chance or</li>
<li>a ratio: 1:5 (out of 6 outcomes we expect for 1 successful outcome and 5 unsuccessful outcomes).</li></ul>

In this course, we usually express probabilities either as an exact value, usually in fraction form, or as a decimal number, rounded either using significant figures or decimal places.

<h5>Calculating theoretical probability</h5>

To calculate the theoretical probability of an event, we need to know the **sample space** of an experiment.

The sample space is the set of all possible outcomes of an experiment.
For example, the sample space for when we roll a die (dice) is the set of the six possible outcomes {1,2,3,4,5,6}. In this case, all these outcomes are equally likely.

<p style="text-align: right;"><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/48/Dice_2005.jpg/594px-Dice_2005.jpg?20051223201523" alt="File:Dice 2005.jpg" width="200" height="202" class="img-responsive atto_image_button_right">

When each outcome of an experiment is equally likely, the probability of an event occurring can be calculated by dividing the number of favourable outcomes contained within the event by the total number of outcomes of the experiment.

<h5>Example A (one die)</h5>

Work out the probability of:

<ul>
<li>a) rolling a 4 and</li>
<li>b) work out the probability of rolling a number larger than 3.</li>
</ul>

Solution to a) 

There are 4 outcomes in the sample space {1,2,3,4,5,6}. The event we wish to find is rolling a four, which is just one of six possible outcomes. So the probability of rolling a six, is 1 divided by 6, or \( \frac16 \).
Solution to b) 

To find the probability of rolling a number larger than 3 consider the number of outcomes that "satisfy" this requirement. The three outcomes are: rolling a \(4\), rolling a \(5\) or rolling a \(6\). There are still \(6\) possible outcomes in total and the probability of each is \(\frac16\), so the probability of rolling a number larger than \(3\) is given by \(\frac36\), which equals \(\frac12 \).

<h5>Example B (two dice)</h5>
Now imagine rolling two dice and considering what the possible outcomes are. You could roll a 2 and a 5, or a 5 and a 2. Or two times a 5.
You can picture the sample space as a table:
<div class="editor-indent" style="text-align: center; margin-left: 30px;"><img src="images/07/exampleB.png" alt="" width="300" height="227" role="presentation" class="img-responsive atto_image_button_text-bottom"></div>

Note that the outcomes (2,3) and (3,2) are not the same. We will come back to this example.

<h4>Theoretical vs. experimental probabilities</h4>
Some probabilities like the ones we just looked at can be understood logically, using theory.
In other cases, we cannot figure out the probability of an event using logic alone. For example, if we wanted to know the probability that a woman from a particular population will be between 1.65 and 1.66 metres tall, we need to <b>collect data</b>, i.e. measure the heights of a large number of women in that population to see how many are between 1.65 and 1.66 metres tall, and use this to estimate the probability for the whole population. We call such a probability an **experimental probability.**

Sometimes, instead of an actual experiment, we can use computer simulations.

Not to put you off but here is Sir David Spiegelhalter's take on the understanding of probability:<p style="text-align: center;"> <video controls="true" title="Sir David Spiegelhalter on Wired"><source src="https://www.youtube.com/watch?v=nuSqWRuz-mU">https://www.youtube.com/watch?v=nuSqWRuz-mU</video>   

## Sets and Venn diagrams

<h4>Sets</h4>
Sets are mathematical objects that are, simply put, collections of elements. The are written with curly brackets.
They are similar to lists, but lists are ordered and allow for repetition.
<h5>Examples</h5>
<ul>
<li>Set of objects on the table: {keys, coffee cup, pen, ...} </li>
<li> Set of people in a room: {Joumana, Julie, Alistair, Yotam} </li>
<li> Set of numbers strictly between 1 and 9: {x | 1 &lt; x &lt; 9}. </li>
<li> The  **universal set** is the set of all objects and depends on the context. The universal set of all socks in the world, or the universal set of all students in the Access course. </li>
<li> The famous <a href="https://en.wikipedia.org/wiki/Russell's_paradox" target="_blank">Russell's paradox</a>: {sets that contain themselves}</li>
</ul>

Sets on their own are interesting, but how they interact with each other is even more so. 
<ul>
<li>The **union **of two (or more) sets are the elements that are in <b>either</b> set. </li>
<li>The <b>intersection</b> of two (or more) sets are the elements that are in <b>both</b> sets.</li>
</ul>
<h5>Examples</h5>
Set of odd numbers between 10 and 20: {11,13,15,17,19}. 

Set of prime numbers between 0 and 15: {2,3,5,7,11,13}. 

The union of the two sets it: {2,3,5,7,11,13,17,19}.

The intersection of the two sets is: {11,13}.

Set of objects on the table: {keys, coffee cup, pen, calculator}. 

Set of things I want to take with me: {keys, pen, wallet}.

The union of the two sets is: {keys, coffee cup, pen, calculator, wallet}

The intersection of the two sets is: {keys,pen}.

<h4>Venn diagrams</h4>

<h5> Joke (from XKCD)</h5> 
<p style="text-align: center;"><img src="images/07/XKCD.png" alt="https://www.comicsenglish.com/wp-content/uploads/2013/05/xkcd-university_website.png" width="301" height="210" class="img-responsive atto_image_button_text-bottom"> 

The intersection between "Things on the front page of a university website" and "Things people go to the site looking for" is only the "Full name of the school". The union is all the entries in the two circles - all the things that are on a university's website and all the things that people are looking for when they navigate to it.
The universal set here is the rectangle drawn around the two sets represented by the circles. It is not clear what it would represent in this case.

A **Venn diagram** is a diagram style that shows the relation between sets, and was invented by English Mathematician and Logician John Venn in the 1880s. As the diagrams can be used to represent sets we can use them to represent probabilities for combinations of different events. 
The circles each represent one set. There can be any number of sets. The rectangle around them is the universal set, denoted \( \mathfrak{U} \).

<h5>Notation</h5>
The **Intersection of A and B: ** \(A \cap B\) 
<p style="text-align: center;"><img src="images/07/Venn diagram - intersection.png" alt="Venn diagram - intersection" width="340" height="211" role="presentation" class="img-responsive atto_image_button_text-bottom"> 
**Not A: **\(A'\). Note that in this case the universal set \( \mathfrak{U} \) is very useful as otherwise the whole page would have to be shaded in! 

<p style="text-align: center;"><img src="images/07/Venn diagram - not A.png" alt="" width="340" height="211" role="presentation" class="img-responsive atto_image_button_text-bottom"> 
**A: **\(A\)
<p style="text-align: center;"><img src="images/07/Venn diagram - A.png" alt="" width="340" height="211" role="presentation" class="img-responsive atto_image_button_text-bottom"> 

**Union A and B: **\(A \cup B\)
<p style="text-align: center;"><img src="images/07/Venn diagram - union.png" alt="" width="340" height="211" role="presentation" class="img-responsive atto_image_button_text-bottom"> 
<h5>Example</h5>
A survey was done on first year students on what they felt made them like some animals more than others. \(42\)% of students responded saying they favoured an animal that was fluffy, while \(28\)% of students responded saying they favoured an animal that had big teeth. \(4\)% of students responded saying they favoured an animal with both of these characteristics.
We can use these data to estimate the probability that a student will favour an animal that is fluffy OR has big teeth, or is fluffy AND has big teeth. 
Below we see a Venn diagram of the probabilities that a student's favourite animal will be fluffy, have big teeth, or be fluffy and have big teeth. 
<p style="text-align: center;"><img src="images/07/Venn diagram - example fluffy.png" alt="example Venn diagram" width="341" height="263" class="img-responsive atto_image_button_text-bottom">

From this diagram you can see for instance that although \(28\%\) of students seem to prefer animals with big teeth, \(24\%\) students preferred them to have big teeth but NOT be fluffy. 

## Laws of probability

Probability is governed by laws which allow us to understand more complicated questions of chance.
<h4>Combining events</h4>
If we have more than one event, we need to start thinking about how to combine the events and their probabilities.
Suppose we have two events called \(A\) and \(B\).
Consider the case where **both** events happen. We can understand this as the **intersection of A and B**, \(A \cap B\). The probability of A <em>and</em> B happening would be \(P(A \cap B)\).
Note that the universal set \( \mathfrak{U} \) would have probability \(1\) here. 
<p style="text-align: center;"><img src="images/07/prob-law1.png" alt="" width="300" height="193" style="font-size: 0.9375rem;">
Consider the case where <em>one or the other or both</em> events happen. We call this the **union of A and B**, \(A \cup B\). The probability of <em>either or</em> events happening is \(P(A \cup B)\).
<p style="text-align: center;"><img src="images/07/prob-law2.png" alt="Union of Venn diagrams" width="301" height="209" style="font-size: 0.9375rem;">
Consider the case where \(A\) <em>does not happen</em>. We call this the **complement of A**, \(A'\) or \(A^c\). The probability of A <em>not </em> happening is \(P(A')\).
<p style="text-align: center;"><img src="images/07/prob-law3.png" alt="" width="200" height="169" role="presentation" style="font-size: 0.9375rem;">
<h5>Example</h5>
Suppose that we roll a six-sided die. The universal set is the set of all possible outcomes: \( \mathfrak{U}={1,2,3,4,5,6} \). Let \(A\) be the event of rolling a number greater than \(2\), and \(B\) rolling an even number. 
The event \(A \cap B\) is therefore the event that we roll a number that is <em>both</em> even <em>and</em> greater than \(2\) (i.e. rolling a \(4\) or a \(6\)). The event \(A \cup B\) is the event that we roll a number that is <em>either</em> greater than \(2\), even <em>or both</em> greater than \(2\) <em>and</em> even (i.e. rolling a \(2, 3, 4, 5\) or \(6\)). The event \(A'\) is the event that we roll a number that is not greater than \(2\) (i.e. rolling a \(1\) or a \(2\)).
<p style="text-align: center;"><img src="images/07/prob-law4.png" alt="" width="319" height="200" role="presentation" class="img-responsive atto_image_button_text-bottom"><img src="images/07/prob-law5.png" alt="" width="317" height="200" role="presentation" class="img-responsive atto_image_button_text-bottom">
\(P (A \cap B) = P(greater~than~2~and~even) =\frac{2}{6}\)
\(P (A \cup B) = P(greater~than~2, ~even,~or~both) = \frac{5}{6}\)
\(P (A') = P(not ~greater ~than ~2) = \frac26\).
<h4>Independence</h4>
Two events, \(A\) and \(B\), are **independent** of one another if the probability that one of the events happens is unaffected by whether or not the other one happens. The events are **dependent** on one another if they are not independent of each other.
<h5>Example 1</h5>
In the experiment of throwing two dice, the outcome of each dice is not influenced by the outcome of the other dice. This means that each outcome is independent from each other.
<h5>Example 2</h5>
The event of me taking my umbrella in the morning is influenced by whether or not it is raining. If it is not raining, the probability that I will take an umbrella is smaller than when it is raining. The two events are therefore not independent, i.e. dependent.
The events of me taking my umbrella in the morning is however not influenced on whether or not the the moon is full or not. Those two events are independent.
<h4>Mutually exclusive </h4>
We say that two events are **mutually exclusive** if they cannot both happen at the same time. For example, we cannot roll both an even and an odd number on a single die, and so the events 'rolling an odd number' and 'rolling an even number' are mutually exclusive. 
<h5>Example</h5>
This is a joke from XKCD. It says that the computer problems that are caused by viruses are never problems that make people say "maybe it has a virus" and vice versa.
<p style="text-align: center;"><img src="http://imgs.xkcd.com/comics/virus_venn_diagram.png" style="font-size: 0.9375rem;">
<h4>Multiplication law</h4>
For <em>independent</em> events, the probability that events \(A\) and \(B\) <em>both </em>occur is equal to product of the probability of event \(A\) and the probability of event \(B\): \(P(A \mbox{ and } B) = P(A \cap B) = P(A) \times P(B)\).
Importantly, this law can be extended for more than two independent events.
<h5>Example 1</h5>
In the example above, the probability of both me taking the umbrella and the moon being full is equal to the product of both. Lets say that on any given day, the probability that I will take my umbrella is 0.1 and the probability that the neighbour's
dog goes for a walk is .95. Then the probability of both happening is: \( 0.1 \times 0.95 = 0.095\). 
<h5>Example 2</h5>
Two six-sided fair dice: Let \(A\) be the event of rolling a \(3\) on the first die and \(B\) be the event of rolling an even number on the second die. Then \[ P(A) = \frac{1}{6} \qquad \text{and} \qquad P(B) = \frac{1}{2} \] Thus the probability that we roll a 3 on the first die and an even number on the second is \[ P(A \cap B) = P(A)P(B) = \frac{1}{6} \times \frac{1}{2}= \frac{1}{12}. \]
<h4>Addition law</h4>
Consider the Venn diagram from above for the union of two events A and B: 
<p style="text-align: center;"><img src="images/07/union.png" alt="" width="201" height="129" role="presentation">
The probability that event \(A\) <em>or</em> event \(B\) occurring is equal to the probability of event \(A\) plus the probability of event \(B\), minus the probability of event \(A \cap B\) : \[ P(A \mbox{ or } B) = P(A) + P(B) - P(A \mbox{ and } B) \] or, equivalently, \[ P(A \cup B) = P(A) + P(B) - P(A \cap B) \] </span> 

If two events are mutually exclusive, then the probability of them both happening is zero. Therefore the law of addition becomes: If \(A\) and \(B\) are mutually exclusive events, then \(P(A \mbox{ or } B) = P(A) + P(B)\), or, equivalently,  \(P(A \cup B) = P(A) + P(B)\) since \(P(A\) and \(B) = P(A \cap B) = 0\).</span> 

<h4>Subtraction law</h4>
Since either A or A' have to happen, the probabilities \(P(A)+P(A') = 1\). Therefore, the probability of \(A\) is equal to 1 minus the probability that event \(A\) will not occur: \[ P(A) = 1 - P(A') \] 
<h4>Law of large numbers</h4>
Consider the graph below. On the horizontal axis, we have the number of times a fair six-sided dice was rolled. On the vertical axis we have value from 1 to 6. The graph represents the average of the results. As the number of times that you roll the die increases, the closer the average comes to the mean average between \(1\) and \(6\), \(3.5\). 
<p style="text-align: center;"><img src="https://upload.wikimedia.org/wikipedia/commons/c/c9/Lawoflargenumbers.svg" alt="law of large numbers dice roll" width="500" height="333" style="font-size: 0.9375rem;" class="img-responsive atto_image_button_text-bottom">
In concrete terms, the law of large numbers means that the proportion of the outcomes will approximate their theoretical probabilities as the number of trials increases. 
For example, if we throw a dice ten times, it is unlikely (in fact impossible) that all six possible outcomes will be equally represented in the outcome. But if you increase the number of times that you roll the dice, each outcome will be more and more equally represented. Set the number of dice to one and then use this Geogebra page to see how the outcomes even out as you throw the dice more often. 
<center><iframe width="600" height="300" src="https://www.geogebra.org/material/iframe/id/UsoH4eNl/width/1000/height/500/border/888888/sri/true/sdz/true" scrolling="no" style="border: 0px;" alt="..."> </iframe></center> 

### Sum of two dice

<h3>Two dice sample space and theoretical vs simulated (experimental) probabilities</h3>The interactive graph below shows the outcome of a simulated experiment in which two dice are rolled a given number of times \(n\), and on each dice roll, the two numbers are added together and recorded. The horizontal axis shows the possible sums of the two dice, the numbers 2 to 12, and the vertical axis shows the number of times each possible sum is obtained. The darker histogram shows the results of the simulated experiment. The paler histogram in the background shows the predicted number of times based on the theoretical probability. 

Moving the slider at the top of the graph allows you to change the number of times the two dice are rolled in the experiment. Pressing the 'Repeat' button repeats the experiment. Investigate how the outcome of the experiment varies as you vary the number of dice rolls and as you repeat the experiment.   

<center> <iframe width="464" height="437" src="https://www.geogebra.org/material/iframe/id/SsdvfSmC/width/464/height/437/border/888888" scrolling="no" style="border: 0px;" alt="Interactive histogram showing the number of times each number between 2 and 12 is obtained in an experiment in which two dice are rolled a number of times. Moving the slider allows the number of times the dice are rolled to be varied, and pressing the 'Repeat' button repeats the experiment. Generally, the larger the number of dice rolls, the more consistent the results are, and the more closely the frequencies match the expected frequency given by the probbility."> </iframe></center>

Since the outcome of each dice roll is random, the results of such an experiment will nearly always vary if the experiment is repeated. Therefore, the probabilities cannot tell us exactly what <em>will</em> happen, only what is <em>most likely</em> to happen.

## Tree diagrams

Just like with data, visualisation can be very helpful in understanding probability. In this course we concentrate on tree diagrams and Venn diagrams.
<table style="margin-left:auto;margin-right:auto;">
<thead>
<tr>
<th scope="col">Example of a tree diagram</th>
</tr>
</thead>
<tbody>
<tr>
<td><img src="https://upload.wikimedia.org/wikipedia/commons/9/9c/Probability_tree_diagram.svg" alt="treediagram example" width="300" height="206" class="img-responsive atto_image_button_text-bottom"></td>
</tr>
</tbody>
</table>
Do not worry about the notation, we will come to that later.
**Tree diagrams** or probability trees are particularly useful when there are several events (not necessarily sequential). They are very useful when investigating dependent probabilities.
<h3>Example</h3>
Suppose we have five counters in a bag of which two counters are blue and three counters are red. We randomly choose two counters from the bag, one after the other without replacing the first one in the bag. The possible outcomes are:
<ul>
<li> choosing either two red counters,</li>
<li> two blue counters or </li>
<li> one of each. </li>
</ul>
In order to calculate these probabilities it is useful to draw a probability tree. In this, we should consider the possible outcomes of drawing the first counter; and then the outcomes of drawing the second counter (given the counter we picked in our first draw) and the associated probabilities of these different events. Event one, is drawing the first counter. Even two, is drawing the second counter.
For this example we obtain the following probability tree: 
<p style="text-align: center;"><img src="images/07/prob-tree.png" alt="" width="300" height="333" role="presentation"> 
The circle on the far left-hand side represents the initial state of the experiment; three red counters and two blue counters in the bag. 
The two branches of the tree leaving this initial circle represent the two outcomes of the first part of our experiment, where we pick one counter out of the bag. The event 'picking a blue counter' is represented by the top branch, and the probability of this happening, \( \frac25 \), is shown next to the branch (there are two blue counters out of a total of five counters). The event 'picking a red counter' is represented by the lower branch, and the probability of this happening, \( \frac35 \), is shown next to this branch. Both branches lead to new circles, which represent the state of the experiment after one counter is drawn from the bag at random.
Each of the two new states have two branches emerging from them. Each branch represents the outcome of having picked either a blue or a red counter on the **second** turn, and the probability of each outcome is shown next to the branch. The four circles on the far right-hand side of the tree represent the final states of the experiment. 
Usually a probability tree is simplified like the following: 
<p style="text-align: center;"><img src="images/07/prob-tree-simp.png" alt="" width="300" height="333" role="presentation"> 
Each path through the tree represents a unique outcome of the experiment. Each path corresponds to independent events. **Hence, the probability of each outcome along a given path is calculated by multiplying together the probabilities on each branch of the given path.** 
For instance, the probability of picking two blue counters is \(P(BB)=\frac25 \times \frac14 = \frac{1}{10}\). 
**Also, these events (paths) are mutually exclusive, and so the probability of one or the other happening is found by adding the probabilities corresponding to the individual paths. **
For instance, the probability of picking a red counter on the second go is \(P( \text{Red on 2nd go}) =\frac25 \times \frac34 +\frac35 \times \frac12=\frac35 \). 

## Conditional probability

<h1></h1>
<p style="text-align: left;">Watch this short video (4:31min) from TED- Ed. Be ready to pause the video to solve the riddle when the video asks you to. 
<p style="text-align: center;"> <video controls="true" title="Ted Ed - the Frog Riddle - Conditional Probability"><source src="https://youtu.be/cpwSGsb-rTs">https://youtu.be/cpwSGsb-rTs</video>  

We will come back to this example in a moment. But first, definitions and vocabulary:
A <b>conditional probability</b> is the probability that an event occurs, <em>given that </em>some other event has occurred. 
For example, it is known that people who smoke are more likely to get lung cancer than those who do not. The probability that an arbitrary person will get lung cancer is quite low, but the probability that a person will get lung cancer, <em>given that</em>    they smoke, is much higher.
Given an event \(A\) and an event \(B\), we write the probability that \(A\) occurs, given that \(B\) has already happened, as \(P(A | B)\). In the above example, we might write \(A\) for the event that a person gets lung cancer, and \(B\) for the event
that that person smokes. Then the probability of a person getting lung cancer, given that they smoke, is \(P(A | B)\).
For our Frog Riddle example, event \(A\) is the croak, event \(B\) is that you get the anti-dote to the poison in the mushroom (i.e. you find a female frog). If you walk right, the probability that you find a female frog is \(50\%\). If you walk left,
the probability is \(P(B | A) = \frac{2}{3}\).
<h3>Conditional probability and dependence</h3>
Conditional probability is important when looking at probabilities of multiple events that are **dependent**. In the above example, the events \(A\) (a person gets lung cancer) and \(B\) (a person smokes) are dependent on one another,
because whether or not someone smokes affects the probability that they get lung cancer. 

We can use conditional probabilities to test whether or not two events are dependent: Two events, \(A\) and \(B\), are independent only if \(P(A|B) = P(A)\), and \(P(B|A) = P(B)\). The probability that someone gets lung cancer given that they smoke is
greater than the general probability that they will get lung cancer, and so \(P(A|B)\) is not equal to \(P(A)\). Therefore, events \(A\) and \(B\) are dependent on one another.
For our Frog riddle example, the two events \(A\) "croak" and \(B\) "one of the two frogs in female" are clearly not independent because the croak tells us that least one of the two frogs is male. The probability that if you have two frogs at least one
of them is female is \(P(B)=\frac{3}{4} =0.75\), but given the croak, \(P(B|A)=\frac{2}{3} \approx 67\%\).

<table>
<thead>
<tr>
<th scope="col"><img src="images/07/cond-prob1.png" alt="" width="299" height="239" role="presentation" class="img-responsive atto_image_button_text-bottom"></th>
<th scope="col"></th>
<th scope="col"><img src="images/07/cond-prob2.png" alt="" width="301" height="191" role="presentation"></th>
</tr>
</thead>
<tbody>
</tbody>
</table>

<h3><span>Calculating conditional probabilities using a tree diagram. </span></h3>
<span>Example</span> 

<span>Suppose a bag contains \(10\) balls, \(6\) red and \(4\) blue. Two balls are chosen (without replacement) at random, one after the other. Consider the two events \(R,\ B\):</span>
<div>
\(R\) is event "first ball chosen is red''
\(B\) is event "second ball chosen  is blue''
</div>
Show that the probability of picking a blue ball second is different to picking a blue ball second given that the first chosen ball was red.
<span>Solution</span>
<span>Perhaps the easiest way of thinking about and calculating with conditional probabilities is to use a tree diagram. In fact, we have met some conditional probabilities in disguise when we examined tree diagrams in the previous section.</span>
<span>Creating a tree diagram for the above situation gives the following:</span> 

<p style="text-align: center;"><img src="images/07/Tree cond prob 1.png" alt="tree diagram of probabilities of picking balls without replacement" width="301" height="356">
Rewriting the branches of this diagram with our above conditional probability notation then gives:
<p style="text-align: center;"> <img src="images/07/Tree cond prob 2.png" alt="tree diagram of probabilities of picking balls without replacement with probability notation" width="297" height="352">
Thus, we can read off the probability of picking a blue ball second given the first ball was red by looking at the second from top branch of the diagram. Thus, \[ P(B|R) = \frac{4}{9}.\] We can work out the probability of picking a blue ball second by
adding up the probability of each branch involving picking a blue ball second, that is \[ P(B) = P(B|R) + P(B|R')= \frac{4}{9} + \frac{3}{9} = \frac{7}{9}.\]
<h3>Calculating conditional probabilities using the formula</h3>
<div>
<h5>Conditional Probability Formula</h5>
Given two events \(A\) and \(B\) then the conditional probability \(\text{P}(B|A)\) is given by: \[ P(B | A) = \frac{P(A \cap B)}{P(A)} \qquad \text{or, equivalently} \qquad P(A \cap B) = P(B|A)P(A).\]
</div>
<h5>Example</h5>
The top shelf has 3 cans of chicken noodle soup and 2 cans of tomato soup. The bottom shelf contains 4 cans of tomoto soup and 1 can of chicken noodle soup. Because it is easier, we are twice as likely to take a can from the bottom shelf (\(P(bottom)=\frac{2}{3}\)) as we
are from the top shelf (\(P(top)=\frac{1}{3}\)). <p style="text-align: center;"><img src="images/07/cans.png" alt="" width="400" height="235" role="presentation" class="img-responsive atto_image_button_text-bottom"> 

Suppose we take a can of soup without paying attention to which one it is, what isa) the probability that is chicken noodle? b) the probability that the can was taken from the top shelf, given that it is chicken noodle soup?
**Solution**

Let event \(T\): the can was taken from the top shelf. \(C\): the chosen soup is chicken noodle soup. 
The probability that the soup is a chicken noodle soup is \(P(C)\). It can be chosen from the top or bottom shelf so \[P(C) = \frac{1}{3} \times \frac{3}{5} +\frac{2}{3} \times \frac{1}{5}  = \frac{5}{15}\] 
The probability that it was taken from the top shelf, given that it is chicken noodle soup is \(P(T|C)\). 
Using the formula \( P(T | C) = \frac{P(T \cap C)}{P(C)}\) we realise that we have \(P(C)\) but not yet the probability that the soup was chosen form the top shelf AND was chicken noodle \(P(T \cap C)\). \[P(C \cap T) = \frac{1}{3} \times \frac{3}{5}
= \frac{3}{15}\]. 
Using the above formula for conditional probability \[ P(T | C) = \frac{P(T \cap C)}{P(C)} \] we therefore have \[ P(T | C) = \frac{\frac{3}{15}}{\frac{5}{15}} = \frac35\]
So the probability that the mushroom soup came from the top shelf is \(0.6\). Note that the order is important. If we asked, what is the probability that it is chicken noodle soup, given that the can came from the top shelf, the answer would be \[ P(C | T) = \frac{P(T \cap C)}{P(T)} \] we therefore have \[ P(T | C) = \frac{\frac{3}{15}}{\frac{1}{3}} = \frac{9}{15}=\frac35\] which makes sense given that there are three chicken noodle soups out of five on the top shelf.
